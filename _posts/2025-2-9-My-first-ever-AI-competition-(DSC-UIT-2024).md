---
title: My first ever AI competition (DSC UIT 2024)
date: 2025-2-9 22:00:00 +0700  
last_modified_at: 2025-02-11 22:00:00 +0700
categories: [Learning, Competition]  
tags: [vn, vlm, school-competition, fine-tuning, datascience, kaggle, colab]  
description: Some stories behind my first AI competition in my university.
author: BFC  
image:  
  path: assets/local/dsc_uit.png
# render_with_liquid: false  
# toc: false  
comments: true  
---  

ChÃ o má»i ngÆ°á»i :vv, hÃ´m nay mÃ¬nh sáº½ chia sáº» láº¡i vá» láº§n Ä‘áº§u tiÃªn mÃ¬nh (tháº­t sá»±) thi má»™t cuá»™c thi vá» AI.  
> BÃ i viáº¿t nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n khÃ¡ lÃ¢u ká»ƒ tá»« ngÃ y thi xong, nÃªn quan Ä‘iá»ƒm vÃ  gÃ³c nhÃ¬n cÃ³ thá»ƒ khÃ¡c vá»›i lÃºc vá»«a hoÃ n thÃ nh cuá»™c thi.  

> Má»i ngÆ°á»i cÃ³ thá»ƒ Ä‘á»c [write-up](https://github.com/BFCmath/DataScienceChallenge-UIT2024), cÃ²n trong bÃ i viáº¿t nÃ y mÃ¬nh chá»§ yáº¿u nÃ³i vá» toÃ n bá»™ quÃ¡ trÃ¬nh thi.  

## Cuá»™c thi AI Ä‘áº§u tiÃªn (not really)  

Náº¿u gá»i Ä‘Ã¢y lÃ  cuá»™c thi AI Ä‘áº§u tiÃªn mÃ¬nh tham gia thÃ¬ cÅ©ng khÃ´ng chÃ­nh xÃ¡c láº¯m. MÃ¬nh tá»«ng tham gia AI Challenge vá»›i bá»n báº¡n, nhÆ°ng mÃ  nÃ³i chung káº¹t quÃ¢n sá»± nÃªn cÅ©ng khÃ´ng tháº­t sá»± "thi" cho láº¯m :v.  

NÃªn lÃ  mÃ¬nh coi Data Science Challenge má»›i lÃ  cuá»™c thi Ä‘áº§u tiÃªn mÃ¬nh tháº­t sá»± tham gia.  

## Tá»•ng quan vá» cuá»™c thi  

Data Science Challenge lÃ  cuá»™c thi do UIT (TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡ ThÃ´ng tin) tá»• chá»©c.  

CÃ³ 2 báº£ng: báº£ng A cho hackathon, báº£ng B cho code challenge. MÃ¬nh tham gia báº£ng B (vÃ¬ mÃ¬nh khÃ´ng tháº­t sá»± thÃ­ch hackathon :v haha).  

Chá»§ Ä‘á» cá»§a nÄƒm nay lÃ  phÃ¡t hiá»‡n chÃ¢m biáº¿m trong cÃ¡c bÃ i post trÃªn máº¡ng xÃ£ há»™i.  

VÃ¬ Ä‘Ã¢y lÃ  DS competition (DS: Data Science) nÃªn hiá»ƒn nhiÃªn lÃ  ngÆ°á»i tham gia sáº½ Ä‘Æ°á»£c cung cáº¥p data (Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n) vÃ  sáº½ cÃ³ benchmark Ä‘á»ƒ xÃ¡c Ä‘á»‹nh ngÆ°á»i tháº¯ng.  

+ **Data**: Texts vÃ  images  
+ **Label**: Multi-class  
+ **Eval function**: F1 score  
+ **Chá»‰ Ä‘Æ°á»£c sá»­ dá»¥ng pretrained model**  
+ **KhÃ´ng sá»­ dá»¥ng thÃªm data bÃªn ngoÃ i**  

## TrÆ°á»›c khi thi  
+ TrÆ°á»›c Ä‘Ã³ thÃ¬ mÃ¬nh tá»± há»c (lÃ½ thuyáº¿t) lÃ  chá»§ yáº¿u, cÃ¡c kiáº¿n thá»©c lÃºc Ä‘Ã³ má»›i thÃ¬ háº§u háº¿t náº±m á»Ÿ Machine Learning. CÃ²n vá» Deep Learning thÃ¬ háº§u háº¿t chá»‰ biáº¿t khÃ¡i niá»‡m vá» transformer, CNN, RNN,... thÃ´i =)), nÃ³i chung lÃ  cháº£ biáº¿t gÃ¬ háº¿t hehe (tháº­m chÃ­ chá»‰ lÃ  biáº¿t khÃ¡i niá»‡m vÃ  Ã½ tÆ°á»Ÿng, cÃ²n cháº£ biáº¿t code nÃ³ ra lÃ m sao :v).  
+ Thi vá»›i tÃ¢m tháº¿ há»c há»i vÃ  thá»­ sá»©c.  

## QuÃ¡ trÃ¬nh thi  

### Giai Ä‘oáº¡n tÃ¬m hiá»ƒu vá» chá»§ Ä‘á»  
NhÃ¬n vÃ o data lÃ  tháº¥y cÃ³ 2 cÃ¡i chÃ­nh:  
+ Data há»—n há»£p  
+ Sarcasm detection  

NÃªn mÃ¬nh cÅ©ng Ä‘i tÃ¬m hiá»ƒu thá»­ xem data há»—n há»£p Ä‘Æ°á»£c giáº£i quyáº¿t nhÆ° tháº¿ nÃ o vÃ  cÃ¡c paper vá» sarcasm detection tiáº¿p cáº­n bÃ i toÃ¡n ra sao.  

Káº¿t quáº£:  
+ Vá» sarcasm detection, há»“i thi mÃ¬nh cháº£ tÃ¬m ra Ä‘Æ°á»£c nhiá»u tÃ i liá»‡u láº¯m (cÃ³ thá»ƒ do thiáº¿u ká»¹ nÄƒng research), kiáº¿m Ä‘Æ°á»£c bÃ i nÃ o thÃ¬ cÅ©ng cháº£ liÃªn quan tá»›i bÃ i toÃ¡n cá»§a mÃ¬nh :v.  
+ CÃ²n vá» data há»—n há»£p cÅ©ng gáº§n nhÆ° báº¿ táº¯c ná»‘t (do thiáº¿u ká»¹ nÄƒng research).  

**CÃ¡ch mÃ¬nh vÆ°á»£t qua giai Ä‘oáº¡n nÃ y?** CÃ¡i nÃ y khÃ¡ hÃ i hÆ°á»›c :v. Do cuá»™c thi giá»›i háº¡n sá»‘ lÆ°á»£ng pretrained models vÃ  yÃªu cáº§u thÃ­ sinh pháº£i ná»™p trÆ°á»›c danh sÃ¡ch models há» sáº½ dÃ¹ng, mÃ  cÃ¡i file Ä‘Ã³ thÃ¬ ai cÅ©ng cÃ³ thá»ƒ access =)). NÃªn mÃ¬nh nháº£y vÃ o Ä‘Ã³ xem thá»­ models cá»§a cÃ¡c báº¡n/anh khÃ¡c rá»“i kiáº¿m paper Ä‘á»c thÃ´i :vvv.  

Nhá» vá»¥ nÃ y mÃ¬nh má»›i biáº¿t Ä‘Æ°á»£c cÃ¡ch Vision Language Model hoáº¡t Ä‘á»™ng, cÅ©ng nhÆ° biáº¿t tá»›i Hugging Face.  

NÃ³i chung, dÃ¹ thiáº¿u kiáº¿n thá»©c tráº§m trá»ng, nhÆ°ng ráº¥t may lÃ  mÃ¬nh váº«n lá»¥m Ä‘Æ°á»£c cÃ¡c model vÃ  paper ngon Ä‘á»ƒ Ä‘á»c, hiá»ƒu thÃªm vá» bÃ i toÃ¡n haha :v, vÃ­ dá»¥ nhÆ° InternVL, LLaVA...  

> **BÃ i há»c**: Ká»¹ nÄƒng research quan trá»ng láº¯m =))  

### Giai Ä‘oáº¡n tÃ¬m hiá»ƒu vá» data  
LÃºc nÃ y mÃ¬nh hÆ¡i non, nÃªn cháº£ biáº¿t nhiá»u ká»¹ thuáº­t EDA cho text cÅ©ng nhÆ° image :v, nÃªn dÆ°á»ng nhÆ° mÃ¬nh chá»‰ quan tÃ¢m tá»›i labels trong cuá»™c thi nÃ y.  

ÄÃ¢y lÃ  má»™t bÃ i toÃ¡n cÃ³ **imbalanced dataset**:  
+ **Train Set**: 10,805 instances (6,062 not-sarcasm, 4,224 multi-sarcasm, 77 text-sarcasm, 442 image-sarcasm)  
+ **Test Set**: 1,413 instances cho public test, 1,504 instances cho private test  

Kiá»ƒm tra thÃªm má»™t Ã­t vá» text cÅ©ng nhÆ° image, mÃ¬nh nháº­n ra Ä‘Ã¢y chá»§ yáº¿u lÃ  post tá»« cÃ¡c meme group trÃªn Facebook.  

Má»™t Ä‘iá»u thÃº vá»‹ lÃ  cÃ¡c post tá»« meme group Ä‘Æ°á»£c chia Ä‘á»u cho cáº£ train vÃ  public test, nÃªn náº¿u khÃ´ng cáº©n tháº­n thÃ¬ dá»… bá»‹ overfitting (giá» nhÃ¬n láº¡i má»›i tháº¥y =)), há»“i thi cháº£ biáº¿t gÃ¬ nÃªn bá»‹ overfit trÃªn táº­p test).  

NgoÃ i ra thÃ¬ má»™t post cÃ³ thá»ƒ cÃ³ nhiá»u images, nÃªn viá»‡c trÃ¹ng caption (text) cÃ³ xáº£y ra.  

## QuÃ¡ trÃ¬nh submit láº§n Ä‘áº§u  

### Github, Hugging Face vÃ  Colab  
NhÆ° mÃ¬nh Ä‘Ã£ nÃ³i, mÃ¬nh dá»±a vÃ o model tá»« file pretrained model mÃ  cÃ¡c thÃ­ sinh gá»­i.  

Tuy nhiÃªn, váº¥n Ä‘á» xáº£y ra lÃ  **lÃ m sao Ä‘á»ƒ dÃ¹ng Ä‘Æ°á»£c cÃ¡c pretrained model Ä‘Ã³?** =))  

Há»“i Ä‘Ã³ mÃ¬nh cá»© nghÄ©, cÃ³ Ä‘Æ°á»£c Github cá»§a model, clone vá» cháº¡y lÃ  xong. NhÆ°ng Ä‘á»i khÃ´ng nhÆ° lÃ  mÆ¡ :v. NÃ³i chung sáº½ cÃ³ 2 váº¥n Ä‘á» chÃ­nh:  
+ Model khÃ´ng support training, chá»‰ support replicate láº¡i káº¿t quáº£ paper  
+ Python library version collision  

NÃ³i chung lÃ  báº¿ táº¯c :v, cháº£ dÃ¹ng Ä‘Æ°á»£c model nÃ o háº¿t. May lÃ  lÃºc nÃ y mÃ¬nh biáº¿t tá»›i Hugging Face (cÅ©ng tá»« cÃ¡i file pretrained model ná»‘t).  

Ngáº¯n gá»n thÃ¬ Hugging Face giÃºp mÃ¬nh chá»‰ qua vÃ i dÃ²ng code lÃ  cháº¡y Ä‘Æ°á»£c model luÃ´n, trÃ¡nh Ä‘Æ°á»£c 2 váº¥n Ä‘á» trÃªn.  

VÃ  cÅ©ng nhá» Hugging Face mÃ  mÃ¬nh tháº­t sá»± biáº¿t dÃ¹ng Colab. Hugging Face thÆ°á»ng cÃ³ finetune hoáº·c inference script hÆ°á»›ng dáº«n cháº¡y trÃªn Colab, nÃªn chá»‰ cáº§n vÃ i cÃº click lÃ  cháº¡y Ä‘Æ°á»£c model :vv  

### TÃ¬m model phÃ¹ há»£p  
DÃ¹ váº­y, lÃºc Ä‘Ã³ mÃ¬nh khÃ´ng Ä‘á»§ thá»i gian há»c cÃ¡ch dÃ¹ng Hugging Face má»™t cÃ¡ch bÃ i báº£n, nÃªn chá»‰ dÃ¹ng vÃ  Ä‘iá»u chá»‰nh script cÃ³ sáºµn cá»§a cÃ¡c model thÃ´i :(.  

ChÃ­nh Ä‘iá»u Ä‘Ã³ Ä‘Ã£ háº¡n cháº¿ ráº¥t lá»›n sá»‘ model mÃ  mÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng.  

Sau má»™t há»“i dÃ² xÃ©t, ráº¥t may máº¯n lÃ  váº«n cÃ³ má»™t vÃ i model cÃ³ script finetune cháº¡y Ä‘Æ°á»£c. VÃ  model Ä‘áº§u tiÃªn mÃ¬nh chá»n lÃ  **[ViLT](https://arxiv.org/pdf/2102.03334)**.  

### Fine-tuning ViLT  
Sau khi Ä‘á»c paper cá»§a ViLT, kiá»ƒm tra script vÃ  cháº¡y thá»­, mÃ¬nh nháº­n ra ViLT chá»‰ output ra Ä‘Æ°á»£c má»™t chá»¯. ÄÃ o sÃ¢u hÆ¡n thÃ¬ má»›i hiá»ƒu ráº±ng output cuá»‘i cÃ¹ng cá»§a ViLT dÃ nh cho classification task.  

Ráº¥t may lÃ  mÃ¬nh tá»«ng Ä‘á»c qua paper cá»§a BERT vÃ  cÃ³ chÃºt kiáº¿n thá»©c vá» classification model (tá»« CNN), nÃªn cÅ©ng biáº¿t cÃ¡ch Ä‘á»•i head cá»§a nÃ³ thÃ nh sá»‘ class cho bÃ i toÃ¡n cá»§a mÃ¬nh.  

LÃºc Ä‘Ã³ mÃ¬nh freeze cÃ¡c layer á»Ÿ dÆ°á»›i vÃ  chá»‰ train head layer.  

**Káº¿t quáº£ khÃ¡ sá»‘c** :v, lÃªn háº¡ng nháº¥t luÃ´n =)). (MÃ¬nh nhá»› táº§m **0.38 F1 score**).  

> **Giá» nhÃ¬n láº¡i thÃ¬ cÃ³ thá»ƒ giáº£i thÃ­ch vÃ¬ sao:**  
> + Giai Ä‘oáº¡n Ä‘áº§u cá»§a cuá»™c thi (sau nÃ y top 1 public score lÃªn tá»›i **44%** =)))  
> + **Overfitting** (nhÆ° Ä‘Ã£ nÃ³i á»Ÿ trÃªn, test data cÃ³ nhiá»u Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng vá»›i train data)  

## Má»™t vÃ i thá»­ nghiá»‡m vá»›i ViLT  

Sau Ä‘Ã³ thÃ¬ mÃ¬nh cÃ³ thá»­ nghiá»‡m má»™t sá»‘ thá»©.  

### Äiá»u chá»‰nh input  
Há»“i Ä‘Ã³ thÃ¬ mÃ¬nh khÃ´ng hiá»ƒu láº¯m vá» cÃ¡c ká»¹ thuáº­t training, nÃªn thá»­ nhiá»u thá»© mÃ  mÃ¬nh cho ráº±ng lÃ  há»£p lÃ½. Cháº³ng háº¡n nhÆ° thÃªm: "`HÃ£y phÃ¢n loáº¡i bÃ i post sau thÃ nh 4 class... <caption> <image>`"  

> Sau nÃ y mÃ¬nh má»›i biáº¿t cÃ¡i pháº§n thÃªm vÃ o Ä‘Ã³ gá»i lÃ  **instruction**.  

NgoÃ i ra, mÃ¬nh cÅ©ng thá»­:  
- Äiá»u chá»‰nh kÃ­ch thÆ°á»›c cá»§a image.  
- XÃ³a icon.  
- Äá»•i cÃ¡c tá»« viáº¿t táº¯t.  
- XÃ³a hashtag.  
- Äá»•i cÃ¡c tá»« bá»‹ che thÃ nh khÃ´ng che (vÃ­ dá»¥: c.h.Ã³ â†’ chÃ³).  

> LÃºc Ä‘Ã³ mÃ¬nh khÃ´ng há» biáº¿t tá»›i cÃ¡c ká»¹ thuáº­t Ä‘Æ¡n giáº£n Ä‘á»ƒ xá»­ lÃ½ text luÃ´n haha =))  

### Multilabel Classification  

Qua má»™t vÃ i quan sÃ¡t Ä‘Æ¡n giáº£n, mÃ¬nh nháº­n ra bÃ i toÃ¡n nÃ y cÃ³ thá»ƒ gom cÃ¡c class láº¡i vá»›i nhau vÃ  biáº¿n nÃ³ thÃ nh má»™t **multilabel classification task**.  

CÃ¡i nÃ y hoÃ n toÃ n má»›i vá»›i mÃ¬nh :v, nÃªn mÃ¬nh nháº£y Ä‘i Ä‘á»c paper luÃ´n. Má»™t paper mÃ  mÃ¬nh há»c Ä‘Æ°á»£c ráº¥t nhiá»u lÃ : **[A Survey on Multilabel Learning in Deep Learning](https://arxiv.org/pdf/2401.16549)**.  

Qua paper nÃ y, mÃ¬nh biáº¿t thÃªm vá» cÃ¡c hÃ m loss Ä‘Æ°á»£c dÃ¹ng cho bÃ i toÃ¡n multilabel classification.  

MÃ¬nh cÃ³ Ã¡p dá»¥ng thá»­, nhÆ°ng mÃ  fail :vv, khÃ´ng cÃ³ cÃ¡i nÃ o Ä‘áº¡t Ä‘Æ°á»£c hÆ¡n **0.39 F1 score** cáº£.  

**Káº¿t quáº£:** VÃ i ngÃ y sau rá»›t top :v.  

### Hyperparameter tuning vÃ  Freezing layer  
MÃ¬nh chá»§ yáº¿u test **learning rate** (lÃºc Ä‘Ã³ chÆ°a biáº¿t cÃ¡ch dÃ¹ng scheduler).  

NgoÃ i ra, mÃ¬nh cÃ²n thá»­ cÃ¡c chiáº¿n thuáº­t **freeze layer** khÃ¡c nhau:  
+ **Unfreeze hoÃ n toÃ n.**  
+ **Unfreeze lá»›p input embedder.**  
+ **Unfreeze lá»›p attention.**  
+ **Unfreeze má»™t sá»‘ lá»›p nhá» trong lá»›p attention.**  

CÃ¹ng vá»›i Ä‘Ã³, mÃ¬nh test cÃ¡c loss function nhÆ° **Weighted Cross-Entropy (CE)** vÃ  thá»­ nghiá»‡m nhiá»u trá»ng sá»‘ khÃ¡c nhau Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» imbalance.  

## Traditional Machine Learning Approach  

TrÆ°á»›c giá» mÃ¬nh chÆ°a thi cuá»™c thi Deep Learning nÃ o, háº§u háº¿t lÃ  toÃ n vá»c code Machine Learning thÃ´i. NÃªn mÃ¬nh cÅ©ng cá»‘ gáº¯ng Ä‘Æ°a bÃ i toÃ¡n nÃ y vá» **traditional ML**.  

MÃ¬nh khÃ´ng nhá»› rÃµ láº¯m, nhÆ°ng mÃ¬nh cÃ³ táº¡o ra má»™t sá»‘ features nhÆ°:  
- Sá»‘ lÆ°á»£ng icon.  
- Sá»‘ lÆ°á»£ng chá»¯.  
- Sá»‘ lÆ°á»£ng hashtag.  
- ...  

VÃ  cháº¯c cÃ¡c báº¡n cÅ©ng Ä‘oÃ¡n Ä‘Æ°á»£c káº¿t quáº£ rá»“i =))))))  

> Sau nÃ y Ä‘á»c nhiá»u paper hÆ¡n, mÃ¬nh má»›i hiá»ƒu vÃ¬ sao láº¡i fail, chá»© lÃºc Ä‘Ã³ cÅ©ng khÃ¡ tá»± tin :v.  

NgoÃ i ra, mÃ¬nh cÅ©ng cÃ³ vÃ i suy Ä‘oÃ¡n Ä‘áº¡i loáº¡i kiá»ƒu **ViLT khÃ´ng hiá»ƒu Ä‘Æ°á»£c icon** (há»“i Ä‘Ã³ cÃ²n cháº£ biáº¿t dÃ¹ng tokenizer Ä‘á»ƒ kiá»ƒm tra cÃ¡i suy Ä‘oÃ¡n nÃ y). Náº¿u biáº¿t cÃ¡ch, mÃ¬nh hoÃ n toÃ n cÃ³ thá»ƒ **custom láº¡i model Ä‘á»ƒ táº­n dá»¥ng cÃ¡c features nÃ y**.  
Táº¥t nhiÃªn lÃ  mÃ¬nh Ä‘Ã£ khÃ´ng thá»ƒ lÃ m váº­y vÃ¬ lÃºc Ä‘Ã³ chÆ°a biáº¿t tá»›i ká»¹ thuáº­t nÃ y ğŸ˜­.  


## TÃ¬m models lá»›n hÆ¡n 
Sau vÃ i ngÃ y thá»­ nghiá»‡m vá»›i ViLT, mÃ¬nh nhÃ¬n láº¡i báº£ng xáº¿p háº¡ng thÃ¬ tháº¥y bá»‹ bá» khÃ¡ xa (cao nháº¥t lÃºc Ä‘Ã³ cá»§a mÃ¬nh lÃ  0.39 trong khi cÃ¡c thÃ­ sinh khÃ¡c Ä‘Ã£ gáº§n tá»›i 0.41). NÃªn mÃ¬nh quyáº¿t Ä‘á»‹nh sá»­ dá»¥ng chiáº¿n thuáº­t cÅ© Ä‘á»ƒ tÃ¬m finetune script tá»« cÃ¡c model khÃ¡c Ä‘á»ƒ test. 

### Váº¥n Ä‘á» vá» GPU
Trong quÃ¡ trÃ¬nh mÃ¬nh tÃ¬m, cÃ³ ráº¥t nhiá»u models lá»›n lÃªn tá»›i hÆ¡n máº¥y tá»· tham sá»‘ nhÆ°: InternVL, LLaVa, Mistral vÃ  Qwen-VL. 

MÃ¬nh cÅ©ng khÃ¡ hÃ o há»©ng thá»­ tá»«ng cÃ¡i, do lÃ  model lá»›n, nÃªn cá»™ng Ä‘á»“ng cÅ©ng lá»›n, kÃ¨m theo ráº¥t nhiá»u script, video vÃ  blog cÃ³ thá»ƒ há»c há»i Ä‘Æ°á»£c. 

Tuy váº­y, cÃ³ vÃ i váº¥n Ä‘á» xuáº¥t hiá»‡n khiáº¿n mÃ¬nh khÃ´ng thá»ƒ dÃ¹ng Ä‘Æ°á»£c cÃ¡c model trÃªn:
+ Cáº§n GPU hopper, cá»¥ thá»ƒ hÆ¡n, cÃ¡c model nÃ y sá»­ dá»¥ng flash attention 2.0(?) vÃ  vá»›i cÃ¡c nguá»“n GPU miá»…n phÃ­ thÃ¬ khÃ´ng thá»ƒ nÃ o dÃ¹ng Ä‘Æ°á»£c flash attention.
+ KhÃ´ng há»— trá»£ tiáº¿ng Viá»‡t.
+ Cáº§n quÃ¡ nhiá»u VRAM, cÃ¡c models vá»›i 2B vÃ  7B tham sá»‘, mÃ¬nh khÃ´ng tÃ i nÃ o nhÃ©t vá»«a Ä‘Æ°á»£c vá»›i cÃ¡c má»©c GPU free.

### Kaggle
Tá»›i Ä‘Ã¢y, mÃ¬nh cÅ©ng nháº­n tháº¥y sá»± quan trá»ng cá»§a GPU, vÃ  báº¯t Ä‘áº§u sá»­ dá»¥ng má»™t nguá»“n GPU KhÃ¡c ngoÃ i Google Colab, Ä‘Ã³ lÃ  Kaggle.

Kaggle tháº­t sá»± tuyá»‡t vá»i nhÆ°ng khÃ´ng dá»… Ä‘á»ƒ dÃ¹ng tá»‘i Æ°u ngay láº§n Ä‘áº§u sá»­ dá»¥ng.

VÃ  mÃ¬nh cÃ³ háº³n 1 [repo](https://github.com/BFCmath/FinetuneAI_Learning) share cÃ¡ch mÃ¬nh sá»­ dá»¥ng Kaggle vÃ  Colab sao cho hiá»‡u quáº£ nháº¥t. 

Cháº¯c mÃ¬nh sáº½ lÃªn 1 bÃ i vá» viá»‡c nÃ y sau (náº¿u ráº£nh), cÃ²n trong bÃ i viáº¿t nÃ y xin phÃ©p chá»‰ Ä‘á» cáº­p lÃ  mÃ¬nh Ä‘Ã£ chuyá»ƒn sang Ä‘á»ƒ táº­n dá»¥ng GPU cá»§a Kaggle.

### Vintern 1B 

VÃ  vá»›i viá»‡c chuyá»ƒn sang Kaggle, vÃ  sá»­ dá»¥ng chiáº¿n thuáº­t dÃ² tÃ¬m model cá»§a mÃ¬nh. Ráº¥t may máº¯n lÃ  mÃ¬nh Ä‘Ã£ tÃ¬m ra Ä‘Æ°á»£c 1 model Ä‘á»§ to vÃ  cÃ³ thá»ƒ dÃ¹ng trong Kaggle (2 GPUs). Model Ä‘Ã³ lÃ  cá»§a 1 team Viá»‡t Nam! 

> TrÃ­ch tá»« abstract cá»§a [paper](https://arxiv.org/pdf/2408.12480): In this report, we introduce Vintern-1B (Vietnamese-InternVL2-1B), a reliable 1-billion-parameters multimodal large language model (MLLM) for Vietnamese
 language tasks
 
Model trÃªn vá»«a Ä‘á»§ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» trÆ°á»›c Ä‘Ã³ mÃ¬nh Ä‘á» cáº­p á»Ÿ cÃ¡c model khÃ¡c:
+ Chá»‰ sá»­ dá»¥ng GPU T4 cÅ©ng cÃ³ thá»ƒ cháº¡y Ä‘Æ°á»£c
+ Há»— trá»£ tiáº¿ng Viá»‡t
+ Vá»«a Ä‘á»§ VRAM (Kaggle)

VÃ  ngoÃ i ra, authors cÃ²n ráº¥t tÃ¢m lÃ½ khi ghi háº³n má»™t cÃ¡i [finetune script](https://colab.research.google.com/drive/1bK6fpWfResjv9UxWoKHDStXQ8bop3a6Z?usp=sharing) cho ngÆ°á»i dÃ¹ng, vÃ  solution chÃ­nh cá»§a mÃ¬nh cÅ©ng chá»‰ xoay quanh script nÃ y thÃ´i. 
> Má»™t láº§n ná»¯a cÃ¡m Æ¡n 5CD-AI team, hehe

> Qua vá»¥ nÃ y thÃ¬ má»™t láº§n ná»¯a nháº¥n máº¡nh táº§m quan trá»ng cá»§a GPU, vÃ  viá»‡c phá»¥ thuá»™c vÃ o script tá»« tÃ¡c giáº£ Ä‘Ã£ háº¡n cháº¿ tháº¿ nÃ o vá» solution cá»§a mÃ¬nh.

## CÃ¡c thá»­ nghiá»‡m vá»›i Vintern
### CÃ¡c váº¥n Ä‘á» trÆ°á»›c khi tháº­t sá»± cháº¡y Ä‘Æ°á»£c Vintern
Máº·c dÃ¹ nÃ³i láº¡i thÃ¬ nghe Ä‘Æ¡n giáº£n, nhÆ°ng mÃ  lÃºc Ä‘Ã³ mÃ¬nh váº«n ráº¥t Ä‘au khá»• vá»›i GPU Ä‘á»ƒ cÃ³ thá»ƒ fine-tune Ä‘Æ°á»£c Vintern:
+ QuÃ¡ trÃ¬nh sá»­ dá»¥ng Ä‘Æ°á»£c Kaggle
+ Äiá»u chá»‰nh hyperparemeters Ä‘á»ƒ cÃ³ thá»ƒ fit hoÃ n toÃ n model vÃ o GPUs
+ Äiá»u chá»‰nh script Ä‘á»ƒ cÃ³ thá»ƒ khá»›p vá»›i data cá»§a báº£n thÃ¢n

> BÃ i há»c: pipeline script ráº¥t quan trá»ng vÃ  nÃªn Ä‘Æ°á»£c Æ°u tiÃªn trÆ°á»›c trong Ä‘a sá»‘ trÆ°á»ng há»£p.

### Instruction tuning
Má»™t váº¥n Ä‘á» ráº¥t lá»›n ná»¯a, Ä‘Ã³ lÃ  model cá»§a Vintern, mÃ¬nh khÃ´ng biáº¿t cÃ¡ch chá»‰nh head cá»§a nÃ³ Ä‘á»ƒ biáº¿n nÃ³ tá»« generation task sang classification task
> Non =)), cháº£ biáº¿t nÃ³i gÃ¬ hÆ¡n hehe

ChÃ­nh vÃ¬ tháº¿, nÃªn mÃ¬nh cÃ³ Ä‘i tÃ¬m hiá»ƒu thá»­ cÃ¡ch Ä‘á»ƒ finetune generation task dáº¡ng nÃ y. VÃ  hiá»ƒn nhiÃªn lÃ  mÃ¬nh Ä‘i kiáº¿m tÃ i liá»‡u Ä‘á»c vá» dá»¥ nÃ y rá»“i. Má»™t trong nhá»¯ng tÃ i liá»‡u mÃ¬nh cá»±c kÃ¬ thÃ­ch Ä‘Ã³ lÃ : [The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities](https://arxiv.org/pdf/2408.13296v1)

Má»i ngÆ°á»i cÃ³ thá»ƒ ghÃ© qua Ä‘á»c báº£ng [tÃ³m táº¯t](https://github.com/BFCmath/FinetuneAI_Learning/tree/main/others/papers/UltimateGuideFromBasicsToBreakthrough) cá»§a mÃ¬nh náº¿u tháº¥y ngÃ¡n vá»›i cÃ¡i tÃ i liá»‡u nÃ y.

NhÃ¬n chung thÃ¬ mÃ¬nh há»c Ä‘Æ°á»£c 2 thá»©:
+ PEFT
+ Instruction tuning
> NgoÃ i ra cÃ²n nhiá»u thá»© khÃ¡c mÃ  Ä‘áº¿n láº§n Ä‘á»c thá»© 2, thá»© 3 mÃ¬nh má»›i há»c Ä‘Æ°á»£c.

NhÃ¬n chung, mÃ¬nh sá»­ dá»¥ng LoRA (PEFT) cho bÃ i toÃ¡n nÃ y (GPU issues).
CÃ²n vá» instruction tuning, Ä‘Ã³ chÃ­nh lÃ  kÄ© thuáº­t thÃªm vÃ o 1 lá»i dáº«n (nhÆ° mÃ¬nh Ä‘Ã£ lÃ m vá»›i ViLT) Ä‘á»ƒ khiáº¿n model hiá»ƒu rÃµ hÆ¡n vá» task vÃ  Ä‘Æ°a ra output. 

Output Ä‘á»‘i vá»›i generation task kiá»ƒu nÃ y mÃ¬nh Ä‘á»ƒ háº³n luÃ´n lÃ  "tÃªn" class.

VÃ­ dá»¥: 
+ Input: "`ÄÃ¢y lÃ  má»™t bÃ i viáº¿t trÃªn Facebook cÃ³ thá»ƒ chá»©a hÃ m Ã½ má»‰a mai. ÄÃ¢y lÃ  tiÃªu Ä‘á»: <caption>, Ä‘Ã¢y lÃ  áº£nh cá»§a bÃ i post <image>. Tráº£ vá» cho tÃ´i 1 trong 4 cÃ¢u tráº£ lá»i sau: ...`"
+ Output: "`multi-sarcasm`"
> Táº¥t nhiÃªn generation model cho classification task thÃ¬ sáº½ bá»‹ nhiá»u váº¥n Ä‘á» rá»“i, nhÆ°ng mÃ  biáº¿t gÃ¬ dÃ¹ng náº¥y thÃ´i :>

### KÄ© thuáº­t train trÃªn Kaggle

VÃ¬ váº¥n Ä‘á» GPU, mÃ¬nh khÃ´ng thá»ƒ train vá»›i >= 2 epoch Ä‘Æ°á»£c, nÃªn mÃ¬nh Ä‘Ã£ viáº¿t script cho:
+ train epoch Ä‘áº§u tiÃªn tá»« pretrained weights
+ láº¥y weights tá»« epoch trÆ°á»›c Ä‘Ã³ Ä‘á»ƒ train cho cÃ¡c epoch sau

Viá»‡c train tá»«ng epoch nhÆ° váº­y cÅ©ng giÃºp mÃ¬nh kiá»ƒm soÃ¡t overfitting.
> Trong quÃ¡ trÃ¬nh nÃ y mÃ¬nh cÅ©ng khÃ¡m phÃ¡ ra Ä‘Æ°á»£c data stream cá»§a Kaggle ráº¥t máº¡nh

### Káº¿t quáº£ láº§n Ä‘áº§u submit Vintern
Máº·c dÃ¹ Ä‘au khá»• nhÆ° váº­y, nhÆ°ng káº¿t quáº£ thÃ¬ khÃ´ng phá»¥ lÃ²ng mÃ¬nh. 

MÃ¬nh quay láº¡i top 2 vá»›i Ä‘iá»ƒm khoáº£ng 0.40 f1 score (nÃªn nhá»› lÃ  chÆ°a hyper-tuning).
### More instruction and hyperparameter tuning
Vá»›i Ä‘Ã  nÃ y thÃ¬ mÃ¬nh Ä‘Ã£ táº¡o thÃªm nhiá»u instruction má»›i, bao gá»“m cÃ¡c kÄ© thuáº­t nhÆ° COT...

NgoÃ i ra thÃ¬ cÅ©ng chÆ¡i trÃ² giáº£m dáº§n learning rate cho cÃ¡c epoch sau

Káº¿t quáº£ cao nháº¥t lÃ  khoáº£ng 0.41 f1 score (top 3)
### CÃ¡c váº¥n Ä‘á» (mÃ  sau nÃ y mÃ¬nh má»›i nháº­n ra)
+ MÃ¬nh Ä‘Ã£ khÃ´ng kiá»ƒm soÃ¡t Ä‘Æ°á»£c eval func, chá»‰ cÃ³ loss func thÃ´i (phá»¥ thuá»™c vÃ o script)
+ Generation model cho classification task rÃµ lÃ  khÃ´ng phÃ¹ há»£p
+ Model to háº¡n cháº¿ nhiá»u thá»©, sá»­ dá»¥ng model nhá» sáº½ tá»‘t hÆ¡n á»Ÿ nhiá»u váº¥n Ä‘á»
+ Má»™t váº¥n Ä‘á» ná»¯a lÃ  mÃ¬nh Ä‘Ã£ sá»­ dá»¥ng cÃ¡c tá»« nhÆ° multi-sarcasm, sau khi tokenize ra thÃ¬ cÃ³ thá»ƒ Ä‘Ã¢y lÃ  1 [UNK] (cÃ¹ng vá»›i cÃ¡c class khÃ¡c). Ráº¥t may máº¯n lÃ  Ä‘iá»u Ä‘Ã³ khÃ´ng xáº£y ra.

## Ensemble learning
Vá»›i kiáº¿n thá»©c cá»§a mÃ¬nh tá»« Machine Learning, mÃ¬nh cÅ©ng biáº¿t tá»›i cÃ¡c ensemble learning. 

VÃ  cá»¥ thá»ƒ trong bÃ i nÃ y, táº­n dá»¥ng cÃ¡c hyperparemeter vÃ  instruction khÃ¡c nhau tá»« Vintern, mÃ¬nh Ä‘Ã£ **stack** cÃ¡c output láº¡i Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ tá»‘t hÆ¡n.

CÃ³ vÃ i Ä‘iá»u cáº§n chÃº Ã½: 
+ F1 score sá»­ dá»¥ng lÃ  loáº¡i macro, nghÄ©a lÃ  Ä‘iá»ƒm sá»‘ cao sáº½ pháº£n Ã¡nh kháº£ nÄƒng dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c Ä‘á»‘i vá»›i cÃ¡c lá»›p cÃ³ sá»‘ lÆ°á»£ng máº«u Ã­t.
+ Imbalance data
+ CÃ¡c mÃ´ hÃ¬nh Vintern cá»§a mÃ¬nh gáº·p khÃ³ khÄƒn trong viá»‡c phÃ¡t hiá»‡n cÃ¡c lá»›p cÃ³ sá»‘ lÆ°á»£ng máº«u Ã­t.

ChÃ­nh vÃ¬ tháº¿ nÃªn chá»‰ Ä‘Æ¡n giáº£n láº¥y trung bÃ¬nh sáº½ khÃ³ mÃ  hiá»‡u quáº£, nÃªn mÃ¬nh Ä‘Ã£ viáº¿t cÃ¡c luáº­t (sau Ä‘Ã¢y xin phÃ©p gá»i lÃ  rules) Ä‘á»ƒ Æ°u tiÃªn cho cÃ¡c lá»›p cÃ³ sá»‘ lÆ°á»£ng máº«u Ã­t nÃ y. 

CÃ³ 2 class cáº§n quan tÃ¢m:
+ image-sarcasm
+ text-sarcasm

CÃ¡c model cá»§a mÃ¬nh khÃ´ng há» detect Ä‘Æ°á»£c text-sarcasm, nÃªn mÃ¬nh Ä‘Ã£ khÃ´ng thá»ƒ lÃ m gÃ¬ hÆ¡n ngoáº¡i trá»« bá» class nÃ y.

CÃ²n Ä‘á»‘i vá»›i image-sarcasm thÃ¬ mÃ¬nh Æ°u tiÃªn tuyá»‡t Ä‘á»‘i, tá»©c chá»‰ cáº§n 1 model dá»± Ä‘oÃ¡n 1 máº«u lÃ  image-sarcasm thÃ¬ káº¿t quáº£ cuá»‘i cÃ¹ng cá»§a máº«u Ä‘Ã³ sáº½ lÃ  image-sarcasm.

MÃ¬nh ban Ä‘áº§u chá»‰ stack 2 models vintern láº¡i vá»›i nhau, 1 model cÃ³ káº¿t quáº£ cao nháº¥t trÃªn public leaderboard (lb) vÃ  1 model cÃ³ kháº£ nÄƒng detect Ä‘Æ°á»£c nhiá»u image-sarcasm.

Káº¿t quáº£ lÃªn tá»›i khoáº£ng 0.415 

Sau Ä‘Ã³ mÃ¬nh stack thÃªm 1 model ná»¯a cÃ³ káº¿t quáº£ cao nháº¥t trÃªn táº­p validation thÃ¬ káº¿t quáº£ cao nháº¥t lÃªn tá»›i 0.423 trÃªn lb. VÃ  Ä‘Ã¢y cÅ©ng lÃ  káº¿t quáº£ cao nháº¥t cá»§a mÃ¬nh trÃªn táº­p public test (top 4 trÃªn public lb).

NgoÃ i ra mÃ¬nh cÃ²n test thÃªm meta-learner cho ensemble learning nhÆ°ng khÃ´ng hiá»‡u quáº£. 
> Náº¿u cÃ¡c báº¡n cÃ³ Ä‘á»c write-up thÃ¬ lÃºc Ä‘Ã³ mÃ¬nh cÃ²n khÃ´ng biáº¿t tÃªn cá»§a kÄ© thuáº­t nÃ y lÃ  meta-learning :)) 

## Káº¿t quáº£ cuá»‘i cÃ¹ng trÃªn private test set
Máº·c dÃ¹ top 4 public, nhÆ°ng mÃ  Ä‘iá»ƒm private cá»§a mÃ¬nh láº¡i khÃ¡ áº£m Ä‘áº¡m, cao nháº¥t táº§m 0.405 thÃ´i.

Giáº£i thÃ­ch cho viá»‡c nÃ y thÃ¬ cÃ³ cÃ¡c lÃ­ do chÃ­nh mÃ  bÃ¢y giá» mÃ¬nh má»›i nháº­n ra nhÆ° sau:
+ Thiáº¿u kÄ© nÄƒng sá»­ dá»¥ng Cross-Validation set
+ KhÃ´ng nháº­n biáº¿t overfitting trÃªn táº­p test
+ Model thiáº¿u Ä‘a dáº¡ng (chá»‰ cÃ³ 1 mÃ¬nh Vintern)

## Suy nghÄ© cuá»‘i vÃ  lá»i cÃ¡m Æ¡n
ÄÃ¢y khÃ´ng háº³n lÃ  1 cuá»™c thi lá»›n (so vá» sá»‘ lÆ°á»£ng team tham gia), nhÆ°ng nÃ³ láº¡i ráº¥t phÃ¹ há»£p vá»›i kiáº¿n thá»©c vÃ  má»¥c tiÃªu cá»§a mÃ¬nh lÃºc Ä‘Ã³. 

MÃ¬nh gá»­i lá»i cÃ¡m Æ¡n tá»›i BTC cá»§a DSC-UIT 2024 (náº¿u máº¥y anh/chá»‹/tháº§y/cÃ´ cÃ³ Ä‘á»c Ä‘Æ°á»£c post nÃ y).

Vá» báº£n thÃ¢n thÃ¬ mÃ¬nh Ä‘Ã£ há»c Ä‘Æ°á»£c ráº¥t nhiá»u thá»© má»›i, vÃ  qua bÃ i Ä‘á»c cháº¯c cÃ¡c báº¡n cÅ©ng nháº­n ra Ä‘iá»u Ä‘Ã³.

ÄÃ¢y lÃ  má»™t cuá»™c thi Ä‘áº·t ná»n táº£ng cho nhá»¯ng hÆ°á»›ng Ä‘i (má»¥c tiÃªu) há»c táº­p trÃªn con Ä‘Æ°á»ng tá»± há»c cá»§a mÃ¬nh (ká»ƒ cáº£ khi Ä‘ang soáº¡n post nÃ y). 

CÃ¡m Æ¡n cÃ¡c báº¡n Ä‘Ã£ Ä‘á»c tá»›i Ä‘Ã¢y :)), hÆ¡i dÃ i dÃ²ng vÃ  lÃª thÃª nhÆ°ng mÃ  mÃ¬nh ráº¥t muá»‘n chia sáº» cÃ¢u chuyá»‡n nÃ y Ä‘áº¿n vá»›i má»i ngÆ°á»i. Náº¿u cÃ³ gÃ¬ sai sÃ³t vÃ  cáº§n pháº£i sá»­a Ä‘á»•i, má»i ngÆ°á»i hÃ£y Ä‘á»ƒ láº¡i 1 bÃ¬nh luáº­n nhÃ©!
