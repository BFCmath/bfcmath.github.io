---
title: AI as a prompter
date: 2025-4-21 00:00:00 +0700
categories: [Sharing, Tools]  
tags:  [en, beginner, deep-research, ai, prompt-engineering] 
description: DeepResearch sucks or your promt sucks? (part 2)
author: BFC
image:
  path: assets/local/ai_as_a_prompter.png
# render_with_liquid: false
# toc: false
comments: true
---

## Introduction
Hey everyone, BFC here again!

Not too long ago, I shared a post about using the [AI Prompt Generator for Deep Research](https://bfcmath.github.io/posts/AI-prompt-generator-for-deep-research/). Back then, I mentioned my mixed feelings about deep research tools, but that prompt generator definitely helped me start using (~~maybe abusing~~ ðŸ˜‰) them a lot more.

Today, I want to share a *new* approach I've been experimenting with: using AI itself as an interactive "prompter" to help craft incredibly detailed prompts. This technique has seriously pushed my results to a new level, and I think you might find it useful too!

## Where This Idea Came From

So, my older cousin and I often chat about how we're using AI to tackle different problems. About 3-4 days ago, he mentioned he'd been using [AI Studio](https://aistudio.google.com/) to help *him* generate prompts, and was getting some really impressive results. Basically, he was having AI Studio build the prompts *for* him through conversation. That got me thinking, why not give it a try myself?

## Why This Interactive Approach Might Work Better Than You Think

My cousin listed a few reasons why AI Studio (specifically, I used Gemini 2.5 Pro within it) is great for this:
+   It's free, fast, and has online search and reasoning capabilities (seriously, if you haven't tried the reasoning features, you're missing out!).
+   It has excellent reading comprehension and understands context really well (I've had the same positive experience, lol).

> Funny that I don't have a good experience with AI Studio's code generation capabilities.

## My Experience
Inspired by my cousin, I decided to try this interactive prompting method. Hereâ€™s how I approached it, and honestly, I got some really impressive prompts out of it:

+ I gave Gemini (in AI Studio) an initial prompt that roughly outlined my main request.
+ I *specifically* asked it to have a deep conversation with me to fully understand my needs *before* generating the final prompt. I explicitly told it the goal was a detailed prompt covering all aspects of my request.
+ I instructed it to brainstorm and continuously ask me questions to explore my personal needs, the detailed context (like background, specific goals, constraints, etc.).
+ I then answered every single question it asked me, making sure to provide *even more context* than strictly necessary, even if the AI didn't explicitly ask for certain details. More info seemed better here.
+ We went on talking like this until Gemini had gathered enough information and did not ask any more questions.
+ Finally, it provided the final, detailed prompt based on our entire conversation.

I then took this AI-generated prompt and used it elsewhere â€“ in my case, feeding it into DeepResearch. And it worked like a charm!

## The Results
When I manually reviewed the prompt Gemini generated through this process, I could clearly see it had a much deeper understanding of my request compared to my initial seed prompt. It covered all the angles I needed, and even brought up some points I hadn't initially considered or didn't know how to phrase well.
> Gemini's ability to understand my needs was impressive. It effectively condensed all the dump context into precise and clear keywords for the final prompt. So yes, the more detailed context you feed into the *conversation*, the more complete and targeted the *final prompt* becomes.

The results I got from DeepResearch using this new prompt were significantly better â€“ much more relevant and detailed. Compared to the prompts generated by [Feedough](https://bfcmath.github.io/posts/AI-prompt-generator-for-deep-research/), this interactive method felt like it captured my specific, nuanced needs more effectively.

## Conclusion
So, when might this interactive prompting approach be particularly useful?
*   **You have lots of context/background:** Especially if you're unsure how to best structure it all into a single prompt.
*   **You have lengthy, potentially messy info:** And you're worried the AI might miss key details or keywords if you just dump it all at once.
*   **You need help recalling details:** The back-and-forth conversation actively helps you remember and articulate different facets of your project or goal.
*   **You lack domain-specific keywords:** The AI can help identify more precise terms based on your descriptions, even if you don't know them initially.

Drawbacks? 
*   **Time:** It definitely takes longer to generate the prompt this way compared to just writing one or using a simple generator.
*   **Technique Specificity:** It doesn't automatically incorporate advanced prompting *structures* (like role play) unless you specifically ask it to during the conversation.

Okay, that's all for today! I hope you find this AI-as-a-prompter approach interesting and potentially useful. Give it a try and see how it works for you!

As always, if you have any questions, suggestions, or want to share your own experiences with prompt engineering, feel free to leave a comment below. I'm always learning! ðŸ˜Š
